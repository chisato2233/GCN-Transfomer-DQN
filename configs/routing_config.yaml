# SAGIN Intelligent Routing Configuration
# [FIXED VERSION] - Optimized hyperparameters for better training

# =============================================================================
# Network Topology Configuration
# =============================================================================
network:
  # Node counts
  num_satellites: 3
  num_uavs: 6
  num_ground: 10
  
  # Spatial parameters
  area_size: 10000.0           # meters
  satellite_altitude: 550000.0  # meters (LEO)
  uav_altitude_range: [100.0, 500.0]
  
  # Coverage parameters
  satellite_coverage: 500000.0  # meters
  uav_coverage: 5000.0          # meters
  max_neighbors: 8
  
  # Bandwidth parameters (Hz)
  g2u_bandwidth: 2.0e+7    # Ground to UAV (20 MHz)
  u2u_bandwidth: 1.0e+7    # UAV to UAV (10 MHz)
  u2s_bandwidth: 5.0e+7    # UAV to Satellite (50 MHz)
  s2s_bandwidth: 1.0e+8    # Satellite to Satellite (100 MHz)
  
  # Mobility parameters
  uav_max_speed: 10.0      # m/s
  satellite_orbital_period: 5400  # seconds (~90 minutes)

# =============================================================================
# Environment Configuration
# =============================================================================
environment:
  max_hops: 30              # Maximum hops before timeout (reduced from 50)
  max_neighbors: 8          # Maximum neighbors per node
  history_length: 10        # State history length for Transformer
  topology_update_freq: 10  # Steps between topology updates
  link_failure_prob: 0.02   # Link failure probability (reduced from 0.05)

# =============================================================================
# Reward Configuration [FIXED]
# =============================================================================
reward:
  # Main rewards
  success_bonus: 30.0       # Reward for reaching destination (increased from 10)
  timeout_penalty: 5.0      # Penalty for exceeding max hops (increased)
  
  # Step penalties
  delay_weight: 1.0         # Weight for delay penalty
  loss_weight: 10.0         # Weight for packet loss penalty
  congestion_weight: 0.5    # Weight for congestion penalty
  
  # Behavior penalties
  loop_penalty: 2.0         # Penalty for revisiting nodes (full penalty now)
  invalid_action_penalty: 1.0
  
  # Progress rewards [FIXED - increased]
  progress_reward: 0.5      # Base progress reward (increased from 0.1)

# =============================================================================
# DQN Agent Configuration [FIXED]
# =============================================================================
dqn:
  lr: 5.0e-5                # Learning rate (slightly reduced for stability)
  target_update_freq: 100   # Target network update frequency
  max_grad_norm: 1.0        # Gradient clipping
  use_double_dqn: true      # Use Double DQN
  use_dueling: true         # Use Dueling architecture
  tau: 0.005                # [NEW] Soft update coefficient (was 0.001)

# =============================================================================
# Exploration Configuration [FIXED V3 - Stable Training]
# =============================================================================
exploration:
  epsilon_start: 1.0
  epsilon_end: 0.05         # Minimum exploration rate
  epsilon_decay: 0.995      # [V3] Restored faster decay for stability
  # At 500 episodes: 0.995^500 ≈ 0.08 (quick exploitation)
  # At 300 episodes: 0.995^300 ≈ 0.22 (balanced exploration)

# =============================================================================
# Replay Buffer Configuration [V3 - Larger batch for stability]
# =============================================================================
buffer:
  capacity: 100000          # Replay buffer size
  batch_size: 128           # [V3] Larger batch for stable gradients (was 64)
  use_per: false            # Prioritized Experience Replay
  per_alpha: 0.6            # PER alpha
  per_beta_start: 0.4       # PER beta start
  per_beta_frames: 100000   # PER beta annealing frames

# =============================================================================
# GCN Configuration
# =============================================================================
gcn:
  node_feature_dim: 9       # Node feature dimension
  hidden_dim: 64            # GCN hidden dimension
  output_dim: 64            # GCN output dimension
  max_neighbors: 8          # Maximum neighbors for local GCN
  num_layers: 2             # Number of GCN layers
  dropout: 0.1              # Dropout rate

# =============================================================================
# Transformer Configuration
# =============================================================================
transformer:
  d_model: 64               # Model dimension
  num_heads: 4              # Number of attention heads
  num_layers: 2             # Number of transformer layers
  d_feedforward: 128        # Feedforward dimension
  dropout: 0.1              # Dropout rate
  history_length: 10        # Input sequence length
  max_seq_length: 10        # Maximum sequence length

# =============================================================================
# Feature Fusion Configuration
# =============================================================================
fusion:
  method: "gated"           # Fusion method: "concat", "attention", "gated"
  output_dim: 128           # Fused feature dimension
  dropout: 0.1              # Dropout rate

# =============================================================================
# Training Configuration [FIXED]
# =============================================================================
training:
  num_episodes: 3000        # Maximum training episodes
  max_steps_per_episode: 30 # Max steps per episode (reduced)
  gamma: 0.99               # Discount factor
  
  # Evaluation [FIXED]
  eval_frequency: 50        # Evaluate every N episodes
  num_eval_episodes: 50     # [FIXED] Number of eval episodes (was 20)
  
  # Checkpointing
  save_frequency: 200       # Save checkpoint every N episodes
  log_frequency: 10         # Log every N episodes
  
  # Early stopping [FIXED V2]
  patience: 800             # [V2] More patience for recovery (was 500)
  warmup_episodes: 400      # [V2] Longer warmup, no early stopping during this period

# =============================================================================
# Hardware Configuration
# =============================================================================
hardware:
  device: "cuda"            # Device: "cuda" or "cpu"
  num_workers: 4            # DataLoader workers (if applicable)

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  level: "INFO"
  tensorboard: true
  wandb: false
  save_video: false
